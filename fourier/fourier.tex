\documentclass[a4paper,10pt]{article}
%\documentclass[fleqn]{article}
%\documentclass[a4paper,10pt]{scrartcl}
%\setlength\parindent{0pt}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[margin=0.5in]{geometry}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{mathtools}
\usepackage{subdepth}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
%     \def\Var{[{\rm Var[}\,]}
%     \def\E{{\rm E}\,}
%\newcommand{\E}{\mathrm{E}}
%$\newcommand{\Var}{\mathrm{Var}}$
%$\newcommand{\Cov}{\mathrm{Cov}}$ 
\newcommand{\Exp}[2]{\ensuremath{E_{#1}\left[#2\right]}}
\newcommand{\Log}[2]{\ensuremath{\log_{#1}\left(#2\right)}}
\newcommand{\Vari}[1]{\mathrm{\textit{Var}[\textit{#1}]}}
\newcommand{\Covi}[2]{\mathrm{\textit{Cov}[\textit{#1},\textit{#2}]}} 
\newcommand{\Xsi}{\textit{X}_{i}}
\newcommand{\Ysj}{\textit{Y}_{j}}
\newcommand{\PXsi}{\textit{P}\left(\mathrm{\textit{X}_{i}}\right)}
\newcommand{\PYsj}{\textit{P}\left(\mathrm{\textit{Y}_{j}}\right)}
\newcommand{\mux}{\mu_{\textit{X}}}
\newcommand{\muy}{\mu_{\textit{Y}}}
\newcommand{\sigi}[1]{\sigma_{\textit{#1}}^{2}}
\newcommand{\sigx}{\sigma_{\textit{X}}^{2}}
\newcommand{\sigy}{\sigma_{\textit{Y}}^{2}}
\newcommand{\sigxy}{\sigma_{\textit{XY}}}
\newcommand{\nsbnso}[1]{\overline{{#1}_{Surge\;Blocked}}\cap {#1}_{Surge\;Occurs}}
\newcommand{\nsbgso}[1]{\overline{{#1}_{Surge\;Blocked}} | {#1}_{Surge\;Occurs}}
\newcommand{\sbgso}[1]{{#1}_{Surge\;Blocked} | {#1}_{Surge\;Occurs}}
\newcommand{\so}[1]{{#1}_{Surge\;Occurs}}
\newcommand{\nsb}[1]{\overline{{#1}_{Surge\;Blocked}}}
\newcommand{\nt}[1]{N\left({#1}\right)}
\newcommand{\st}[1]{\ensuremath{_{#1}{S}}}
\newcommand{\fin}[1]{\ensuremath{^{#1}{F}}}
\newcommand{\trans}[2]{\ensuremath{_{#1}^{#2}{T}}}
\newcommand{\matst}[1]{\ensuremath{{_{#1}}{\mathbf{S}}}}
\newcommand{\matfin}[1]{\ensuremath{{^{#1}}{\mathbf{F}}}}
\newcommand{\mattrans}[2]{{\ensuremath{{_{#1}^{#2}}{\mathbf{T}}}}}

\DeclareGraphicsExtensions{.pdf,.png,.jpg,.eps}
\graphicspath{ {./eps/} }

\title{CSE 5301 - Homework 5}
\author{JeffGWood@mavs.uta.edu}
\date{Fall 2014}

\pdfinfo{%
  /Title    ()
  /Author   ()
  /Creator  ()
  /Producer ()
  /Subject  ()
  /Keywords ()
}

\begin{document}
\indent


\noindent\textbf{All Periodic Functions $f(t)$}
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
a_0 &= \dfrac{1}{P}\int_{0}^{P}{f(t)dt}\\
a_n &= \dfrac{2}{P}\int_{0}^{P}{f(t)\cdot\cos\left(\dfrac{2\pi}{P}n\cdot t\right)dt}\\
b_n &= \dfrac{2}{P}\int_{0}^{P}{f(t)\cdot\sin\left(\dfrac{2\pi}{P}n\cdot t\right)dt}\\
\end{split}
\end{equation*}
\newline\noindent\newline\noindent
\noindent\textbf{Complex Number Representation:}
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
e^{i\theta} &= \cos\left(\theta\right)+\sin\left(\theta\right)\cdot i\\
e^{-i\theta} &= \cos\left(-\theta\right)+\sin\left(-\theta\right)\cdot = \cos\left(\theta\right)-\sin\left(\theta\right)\cdot i\\
\cos\left(\theta\right) &= \dfrac{e^{i\theta} + e^{-i\theta}}{2}\\
\sin\left(\theta\right) &= \dfrac{e^{i\theta} - e^{-i\theta}}{2\textit{i}}\\ 
\end{split}
\end{equation*}
\newline\noindent\newline\noindent
\noindent\textbf{Recovery of $f(t)$:}
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
f\left(t\right) &=
\displaystyle\sum_{n=0}^{\infty}{a_n\cdot \cos\left(\dfrac{2\pi}{P}n\cdot t\right)}+
\displaystyle\sum_{n=0}^{\infty}{b_n\cdot \sin\left(\dfrac{2\pi}{P}n\cdot t\right)}\\
&= \dfrac{a_0}{2}+
\displaystyle\sum_{n=1}^{\infty}{a_n\cdot \cos\left(\dfrac{2\pi}{P}n\cdot t\right)}+
\displaystyle\sum_{n=1}^{\infty}{b_n\cdot \sin\left(\dfrac{2\pi}{P}n\cdot t\right)}\\
\end{split}
\end{equation*}


\url{http://www.math.brown.edu/~pflueger/math19/}




%\noindent\textbf{CSE-5301 Homework 1}\\

\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent \textbf{Jeff Wood}\newline
\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent \textbf{Homework\#4b}\newline 
\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent \textbf{CSE-5301}\newline
\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent\indent \textbf{Due: 12/06/2014}\newline
% A special type of binary relation, called an \textbf{\textit{equivalence relation}}, captures the notion of two objects being equal in some feature. A binary relation R is an equivalence relation if R satisfies three conditions: 
\\
\textbf{Important Note:}
\emph{Since there are multiple ways to represent Markov Chains/Models, my solution may not match the notation or format given in Baron. It will be based off of my general knowledge, rather than any specific source.}
\\
\newline\noindent
%\newline\noindent\newline\noindent\textbf{
\textbf{2.a. Show the 1-step transition matrix (5p)}
\newline\noindent\newline\noindent
The single-step probability of \emph{Transitioning} from step $i$ to step $j$ is given by the variable $\trans{i}{j}$. 
A variable that has probability $\st{i}$ of \emph{Starting} in state $i$, has probability of $\fin{j}$ of \emph{Finishing} in state $j$, which is given as:
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
\left[\begin{array}{r}
\fin{1} \\ \fin{2} \\ \fin{3} \\ \fin{4} \\ \fin{5} \\ \fin{6} \\
\end{array}\right]
&=
\left[\begin{array}{rrrrrr}
\trans{1}{1} & \trans{2}{1} & \trans{3}{1} & \trans{4}{1} & \trans{5}{1} & \trans{6}{1} \\
\trans{1}{2} & \trans{2}{2} & \trans{3}{2} & \trans{4}{2} & \trans{5}{2} & \trans{6}{2} \\
\trans{1}{3} & \trans{2}{3} & \trans{3}{3} & \trans{4}{3} & \trans{5}{3} & \trans{6}{3} \\
\trans{1}{4} & \trans{2}{4} & \trans{3}{4} & \trans{4}{4} & \trans{5}{4} & \trans{6}{4} \\
\trans{1}{5} & \trans{2}{5} & \trans{3}{5} & \trans{4}{5} & \trans{5}{5} & \trans{6}{5} \\
\trans{1}{6} & \trans{2}{6} & \trans{3}{6} & \trans{4}{6} & \trans{5}{6} & \trans{6}{6} \\
\end{array}\right]\times
\left[\begin{array}{r}
\st{1} \\ \st{2} \\ \st{3} \\ \st{4} \\ \st{5} \\ \st{6} \\
\end{array}\right]\\
\mathbf{F} &= \mathbf{T}\times\mathbf{S}\\
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
Since for this example we are given the following transition probabilities
\begin{equation*}
\begin{split}
\begin{array}{lllllll}
\text{Begin in State 1:} & \trans{1}{1} = 0.3 & \trans{1}{2} = 0.7 & & & & {\sum}{=1}\\
\text{Begin in State 2:} & \trans{2}{1} = 0.1 & \trans{2}{3} = 0.4 & \trans{2}{4} = 0.5 & & & {\sum}{=1}\\
\text{Begin in State 3:} & \trans{3}{1} = 0.9 & \trans{3}{5} = 0.1 & & & & {\sum}{=1}\\
\text{Begin in State 4:} & \trans{4}{4} = 0.8 & \trans{4}{5} = 0.2 & & & & {\sum}{=1}\\
\text{Begin in State 5:} & \trans{5}{1} = 0.7 & \trans{5}{6} = 0.3 & & & & {\sum}{=1}\\
\text{Begin in State 6:} & \trans{6}{2} = 0.15 & \trans{6}{3} = 0.05 & \trans{6}{5} = 0.4 & \trans{6}{6} = 0.4 & & {\sum}{=1}\\
\end{array}
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
The above transition matrix becomes:
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
\left[\begin{array}{r}
\fin{1} \\ \fin{2} \\ \fin{3} \\ \fin{4} \\ \fin{5} \\ \fin{6} \\
\end{array}\right]
&=\boxed{
\left[\begin{array}{cccccc}
0.3 & 0.1 & 0.9 & 0 & 0.7 & 0 \\
0.7 & 0 & 0 & 0 & 0 & 0.15 \\
0 & 0.4 & 0 & 0 & 0 & 0.05 \\
0 & 0.5 & 0 & 0.8 & 0 & 0 \\
0 & 0 & 0.1 & 0.2 & 0 & 0.4 \\
0 & 0 & 0 & 0 & 0.3 & 0.4 \\
\end{array}\right]}\times
\left[\begin{array}{r}
\st{1} \\ \st{2} \\ \st{3} \\ \st{4} \\ \st{5} \\ \st{6} \\
\end{array}\right]
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
\textbf{2.b. Derive the 3-step transition matrix (hint: matrix multtiplication) (5p)}
\newline\noindent\newline\noindent
The \emph{n}-step transition matrix from time $i$ to time $j$ (where $n=j-i$) is given by $\mattrans{i}{j}$. 
This means a variable with initial state given by $\matst{i}$, has final state $\matfin{j}$
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
{\matfin{j}} &= \mattrans{i}{j}\times\matst{i}\\
{\matfin{j}} &= \left(\mattrans{i}{j}\right)\times\matst{i}\\
{\matfin{j}} &= \left(\mattrans{i}{i+1}\times\mattrans{i+1}{i+2}\times\cdots\times\mattrans{j-2}{j-1}\times\mattrans{j-1}{j} \right)\times\matst{i}\\
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
Since $\mattrans{i}{i+1} = \mattrans{i+1}{i+2} = \cdots = \mattrans{j-2}{j-1} = \mattrans{j-1}{j} = \mathbf{T}$, this becomes
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
\matfin{j} &= \mattrans{i}{j}\times\matst{i}\\
\matfin{j} &= \left(\mattrans{i}{i+1}\times\mattrans{i+1}{i+2}\times\cdots\times\mattrans{j-2}{j-1}\times\mattrans{j-1}{j} \right)\times\matst{i}\\
\matfin{j} &= \left(\mathbf{T} \times \mathbf{T} \times \cdots \times \mathbf{T} \times \mathbf{T}\right)\times{\matst{i}}\\
\matfin{j} &= \left(\mathbf{T}^{j-i}\right)\times{\matst{i}}\\
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
So the the \emph{3}-step transition matrix (say from time $i=0$ to time $j=3$) is given by
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
\mattrans{0}{3} &= \mathbf{T}^{3}\\
&= {\left[\begin{array}{cccccc}
0.3 & 0.1 & 0.9 & 0 & 0.7 & 0 \\
0.7 & 0 & 0 & 0 & 0 & 0.15 \\
0 & 0.4 & 0 & 0 & 0 & 0.05 \\
0 & 0.5 & 0 & 0.8 & 0 & 0 \\
0 & 0 & 0.1 & 0.2 & 0 & 0.4 \\
0 & 0 & 0 & 0 & 0.3 & 0.4 \\
\end{array}\right]}^{3}\\
&= \boxed{\left[\begin{array}{cccccc}
0.3210 & 0.2220 & 0.1650 & 0.1540 & 0.2140 & 0.2955\\
0.1120 & 0.2730 & 0.2425 & 0.1070 & 0.1650 & 0.2800\\
0.0840 & 0.0280 & 0.2535 & 0.0030 & 0.2200 & 0.0380\\
0.3850 & 0.3550 & 0.3150 & 0.5120 & 0.2675 & 0.0900\\
0.0980 & 0.0800 & 0.0120 & 0.1520 & 0.0495 & 0.1350\\
0.0000 & 0.0420 & 0.0120 & 0.0720 & 0.0840 & 0.1615\\
\end{array}\right]}\\
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
\textbf{2.c. Derive the 10-step transition matrix (hint: matrix multiplication) (5p)}
\newline\noindent\newline\noindent
Similaryly, the \emph{10}-step transition matrix from time $i=0$ to time $j=10$ is given by
\newline\noindent\newline\noindent
\begin{equation*}
\begin{split}
\mattrans{0}{10} &= \mathbf{T}^{10}\\
&= {\left[\begin{array}{cccccc}
0.3 & 0.1 & 0.9 & 0 & 0.7 & 0 \\
0.7 & 0 & 0 & 0 & 0 & 0.15 \\
0 & 0.4 & 0 & 0 & 0 & 0.05 \\
0 & 0.5 & 0 & 0.8 & 0 & 0 \\
0 & 0 & 0.1 & 0.2 & 0 & 0.4 \\
0 & 0 & 0 & 0 & 0.3 & 0.4 \\
\end{array}\right]}^{10}\\
&= \boxed{\left[\begin{array}{cccccc}
0.2158 & 0.2141 & 0.2141 & 0.2156 & 0.2170 & 0.2191\\
0.1576 & 0.1597 & 0.1563 & 0.1594 & 0.1587 & 0.1643\\
0.0648 & 0.0661 & 0.0676 & 0.0661 & 0.0683 & 0.0691\\
0.4004 & 0.3985 & 0.4025 & 0.3952 & 0.3984 & 0.3928\\
0.1083 & 0.1076 & 0.1074 & 0.1083 & 0.1062 & 0.1041\\
0.0532 & 0.0540 & 0.0521 & 0.0555 & 0.0513 & 0.0505\\
\end{array}\right]}\\
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
\newpage\noindent
\textbf{2.d. If the intitial state distribution is $P_{0}(X) =(0.5 , 0.25 , 0.15 , 0.05 , 0.05 , 0)$ , what is state distribution after 10 steps $P_{10}(X)$  (hint: vector-matrix multiplication) (10p)}
\newline\noindent\newline\noindent
Setting $\matst{0}=P_{0}(X)=\left[\begin{array}{cccccc} 0.50 & 0.25 & 0.15 & 0.05 & 0.05 & 0.00\end{array}\right]^{T}$, the state distribution at \emph{time} = 10
($\matfin{10}=P_{10}(X)$), is given by
\begin{equation*}
\begin{split}
\matfin{10} &= \mattrans{0}{10}\times\matst{0}\\
&= \left(\mathbf{T}\right)^{10}\times\matst{0}\\
&= {\left[\begin{array}{cccccc}
0.3 & 0.1 & 0.9 & 0 & 0.7 & 0 \\
0.7 & 0 & 0 & 0 & 0 & 0.15 \\
0 & 0.4 & 0 & 0 & 0 & 0.05 \\
0 & 0.5 & 0 & 0.8 & 0 & 0 \\
0 & 0 & 0.1 & 0.2 & 0 & 0.4 \\
0 & 0 & 0 & 0 & 0.3 & 0.4 \\
\end{array}\right]}^{10}\times
\left[\begin{array}{c} 0.5 \\ 0.25 \\ 0.15 \\ 0.05 \\ 0.05 \\ 0\\\end{array}\right]\\
&= \left[\begin{array}{cccccc}
0.2158 & 0.2141 & 0.2141 & 0.2156 & 0.2170 & 0.2191\\
0.1576 & 0.1597 & 0.1563 & 0.1594 & 0.1587 & 0.1643\\
0.0648 & 0.0661 & 0.0676 & 0.0661 & 0.0683 & 0.0691\\
0.4004 & 0.3985 & 0.4025 & 0.3952 & 0.3984 & 0.3928\\
0.1083 & 0.1076 & 0.1074 & 0.1083 & 0.1062 & 0.1041\\
0.0532 & 0.0540 & 0.0521 & 0.0555 & 0.0513 & 0.0505\\
\end{array}\right]\times
\left[\begin{array}{c} 0.5 \\ 0.25 \\ 0.15 \\ 0.05 \\ 0.05 \\ 0\\\end{array}\right]\\
&= \boxed{\left[\begin{array}{c}
0.2152\\
0.1580\\
0.0658\\
0.3999\\
0.1079\\
0.0533\\
\end{array}\right]}
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
\textbf{2.e. Derive the steady state probabilities. (hint: eigenvalue problem) (10p)}
\newline\noindent\newline\noindent
For the markov chain ${\matfin{i+1}}={\mattrans{i}{i+1}}{\times}{\matst{i}}$ we wish to find the vectors of $\matst{i}$ and $\matfin{i+1}$ such that $\matst{i}=\matfin{i+1}$. As an \emph{eigen-value} 
problem this is equivalent to finding the \emph{eigen-vector} ($\mathbf{v}$) corresponding to the \emph{eigen-value} of $\lambda = 1$,
such that $\mathbf{T}{\times}\mathbf{p}=\lambda\cdot\mathbf{p}$.
\newline\noindent\newline\noindent
\emph{MatLab} gives the following vector for the \emph{eigen-value} of $\lambda=1$
\begin{equation*}
\left[
\begin{array}{c}
-0.4324
\\
-0.3189
\\
-0.1329
\\
-0.7971
\\
-0.2159
\\
-0.1080 \\
\end{array}\right]=-2.0052\cdot
\boxed{
\left[\begin{array}{c}
0.2156
\\
0.1590
\\
0.0663
\\
0.3975
\\
0.1077
\\
0.0538 \\
\end{array}\right]
}
\end{equation*}
\newline\noindent\newline\noindent
of which the vector on the right-hand side (which sums to 1 and is therefore the steady-state probability) was obtained by weighting the vector on the left hand side.
\newline\noindent\newline\noindent
We see that
\begin{equation*}
\left[\begin{array}{cccccc}
0.3 & 0.1 & 0.9 & 0 & 0.7 & 0 \\
0.7 & 0 & 0 & 0 & 0 & 0.15 \\
0 & 0.4 & 0 & 0 & 0 & 0.05 \\
0 & 0.5 & 0 & 0.8 & 0 & 0 \\
0 & 0 & 0.1 & 0.2 & 0 & 0.4 \\
0 & 0 & 0 & 0 & 0.3 & 0.4 \\
\end{array}\right]
\times
\left[\begin{array}{c}
0.2156
\\
0.1590
\\
0.0663
\\
0.3975
\\
0.1077
\\
0.0538 \\
\end{array}\right]
=
\left[\begin{array}{c}
0.2156
\\
0.1590
\\
0.0663
\\
0.3975
\\
0.1077
\\
0.0538 \\
\end{array}\right]\\
\end{equation*}
\newline\noindent\newline\noindent
or\\
\newline\noindent\newline\noindent
\begin{equation*}
\left[\begin{array}{cccccc}
0.3 & 0.1 & 0.9 & 0 & 0.7 & 0 \\
0.7 & 0 & 0 & 0 & 0 & 0.15 \\
0 & 0.4 & 0 & 0 & 0 & 0.05 \\
0 & 0.5 & 0 & 0.8 & 0 & 0 \\
0 & 0 & 0.1 & 0.2 & 0 & 0.4 \\
0 & 0 & 0 & 0 & 0.3 & 0.4 \\
\end{array}\right]
\times
\left[\begin{array}{c}
0.2156
\\
0.1590
\\
0.0663
\\
0.3975
\\
0.1077
\\
0.0538 \\
\end{array}\right]
-
\left[\begin{array}{c}
0.2156
\\
0.1590
\\
0.0663
\\
0.3975
\\
0.1077
\\
0.0538 \\
\end{array}\right] = \mathbf{0}
\end{equation*}
\newline\noindent\newline\noindent
\textbf{2.f. What is the expected value of random variable X (hint: if you did 2.e, this should be trivial) (5p)}
\newline\noindent\newline\noindent
Using the vector $\mathbf{X} = \left[\begin{array}{cccccc}5 & 15 & 3 & 5 & 20 & 0\end{array}\right]$, multiplying by the steady-state probability vector gives the expected value of
\begin{equation*}
\begin{split}
E\left[\mathbf{X}\right] &= {\mathbf{X}}{\times}{P_{SS}\left(\mathbf{X}\right)}\\ 
&=\left[\begin{array}{cccccc}5 & 15 & 3 & 5 & 20 & 0\end{array}\right]\times
\left[\begin{array}{c}
0.2156\\
0.1590\\
0.0663\\
0.3975\\
0.1077\\
0.0538\\
\end{array}\right]\\
&=\boxed{7.8035}\\
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
\textbf{2.g. If we want to make sure that every state probability is within 0.01 of its steady state value, how many steps do we need to take from the initial state? (hint: successive matrix multiplications and comparisons) (5p)}
\newline\noindent\newline\noindent
Using the initial probabilities ($\matst{0}$) from \textbf{2.d.}, and applying multiple matrix multiplications of $\mathbf{T}$ we get the following vector for $\matfin{6}$
\begin{equation*}
\begin{split}
\matfin{6}&={\mattrans{0}{6}}{\times}{\matst{0}}\\
&=
\left[
\begin{array}{c}
0.2179\\
0.1587\\
0.0712\\
0.4041\\
0.1031\\
0.0450\\
\end{array}
\right]\\
\end{split} 
\end{equation*}
\newline\noindent\newline\noindent
The difference with the steady state vector is given by 
\begin{equation*}
\begin{split}
{P_{SS}\left(\mathbf{X}\right)} - {\matfin{6}} &=
\left[\begin{array}{c}
0.2179\\
0.1587\\
0.0712\\
0.4041\\
0.1031\\
0.0450\\
\end{array}\right]
-
\left[\begin{array}{c}
0.2156\\
0.1590\\
0.0663\\
0.3975\\
0.1077\\
0.0538\\
\end{array}\right]
=
\left[\begin{array}{r}
0.0023\\
-0.0003\\
0.0049\\
0.0066\\
-0.0046\\
-0.0088\\
\end{array}\right]
\end{split}
\end{equation*}
\newline\noindent\newline\noindent
The maximum difference is given by
\begin{equation*}
\begin{split}
MAX\left({ABS\left({\left[\begin{array}{r}
0.0023\\
-0.0003\\
0.0049\\
0.0066\\
-0.0046\\
-0.0088\\
\end{array}\right]}\right)}\right) &=
MAX\left({\left[\begin{array}{r}
0.0023\\
0.0003\\
0.0049\\
0.0066\\
0.0046\\
0.0088\\
\end{array}\right]}\right)\\
&=0.0088
\end{split}
\end{equation*}
\newline\noindent\newline\noindent
since $0.0088 < 0.01$ this is the first vector with a difference of less than $0.01$ occurring at \boxed{\emph{time} = 6}.
%}
%\newline\noindent
\end{document}