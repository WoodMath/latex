%	Syntax from following sources
%		https://www.sharelatex.com/learn/Sections_and_chapters
%		https://www.sharelatex.com/learn/Table_of_contents
%		http://www.bibtex.org/Using/
%		https://www.economics.utoronto.ca/osborne/latex/BIBTEX.HTM
%		https://www.latex-tutorial.com/tutorials/beginners/latex-bibtex/
%		http://tex.stackexchange.com/questions/205/what-graphics-packages-are-there-for-creating-graphics-in-latex-documents
%		
%% Main stuff
\documentclass[a4paper,10pt]{article}

%% PACKAGES section
\usepackage[utf8]{inputenc}
\usepackage{parskip}

%% Math Packages
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}

%% Date Time Pakcages
\usepackage[USenglish]{babel}
\usepackage[nodayofweek,level]{datetime}
\usepackage[margin=0.5in]{geometry}

%% Formatting Packages
\usepackage{indentfirst}

%% Citation Packages
\usepackage{cite}
\usepackage{hyperref}

%% Table packages
\usepackage{longtable}

%% Color packages
\usepackage{color}

%% COMMANDS section
\newcommand{\logentry}[4]{\hline\\[-0.25ex]\selectlanguage{USenglish}\formatdate{#2}{#1}{#3}&{#4}\par\\[-0.25ex]}

\newcommand{\Kamangar}[1]{%
	{\noindent\textbf{\color{red}Question for Kamangar: }{\noindent #1} \noindent}
}
\newcommand{\NOTE}[1]{%
	{\noindent\textbf{\color{blue}NOTE: }{\noindent #1} \noindent}
}
\newcommand{\SUMMARY}[1]{%
	{\noindent\textbf{\color{blue}SUMMARY: }{\noindent #1} \noindent}
}
\newcommand{\UPDATE}[1]{%
	{\noindent\textbf{\color{blue}UPDATE: }{\noindent #1} \noindent}
}
\title{Research Log}
\author{JeffGWood@mavs.uta.edu}
\date{\today}

\pdfinfo{
  /Title    (Research Log)
  /Author   (Jeff Wood)
  /Creator  ()
  /Producer ()
  /Subject  ()
  /Keywords ()
}

\begin{document}
%% SET section
\setlength\parindent{-10pt}
\setlength{\parskip}{10pt}
\setlength{\parskip}{\baselineskip}
	\maketitle
%% TABLE section
	\begin{longtable}{l p{12cm} }
%%		\hline
		\logentry{3}{30}{2016}{Established research log after 3 hours of learning new \LaTeX}
		\logentry{4}{2}{2016}{Added some additional comments to the \textbf{Process}}
		\logentry{4}{3}{2016}{Have been reading [ImageBasedRendering]~\cite{IBR-Book}.\newline\par 
			\Kamangar{ regarding [ImageBasedRendering]~\cite{IBR-Book} about difference between:
			\begin{itemize}
				\item \textbf{Camera Plane} : Cooridinates \textit{u},\textit{v}
				\item \textbf{Focal Plane} : Cooridinates \textit{s},\textit{t}
			\end{itemize} 
		}}
		\logentry{4}{11}{2016}{Reviewing blog articles located at:
			\begin{itemize}
				\item \url{https://erget.wordpress.com/2014/02/01/calibrating-a-stereo-camera-with-opencv/}
				\item \url{https://erget.wordpress.com/2014/02/28/calibrating-a-stereo-pair-with-python/}
				\item \url{https://erget.wordpress.com/2014/03/13/building-an-interactive-gui-with-opencv/}
				\item \url{https://erget.wordpress.com/2014/04/27/producing-3d-point-clouds-with-a-stereo-camera-in-opencv/}
			\end{itemize}
			for process to get webcam up and running. Previous issues related to fine-tuning \textit{block matching} parameters. Need to review sources at list at bottom of \url{http://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html} to understand.
		}
		\logentry{4}{19}{2016}{%
Made adjustments to python for image acquisition scripts (from blogs mentioned on \formatdate{11}{4}{2016}.) \newline\par
\NOTE{Consider creating rig with glue to keep stereo camera placement / direction constant.}
}
		\logentry{4}{19}{2016}{%
\UPDATE{Error with \texttt{calibrate\_cameras} python code causing linux machine to crash. If can't be resolved switch over to MacBook.}
\newline\par\NOTE{Package should be setup by calling \texttt{\$ python setup.py install.}}}
		\logentry{4}{19}{2016}{%
\UPDATE{Crash due to recursive shell call and was fixed. OpenCV not detecting all chessboard corners. Will try a new board.}}
		\logentry{4}{20}{2016}{Did small amount of work on \textbf{Change of Reference} section in the paper. Added a section to the intro containing a map of commonly used symbols and notation.}
		\logentry{4}{29}{2016}{Read following sections of [Chen1993]~\cite{Chen1993}:
			\begin{itemize}
				\item Abstract
				\item Introduction
				\item Visibility Morphing
			\end{itemize} 
			\quad\par
			\SUMMARY{Explicit Geometry is ignored (i.e. surface mesh and 3d-points). Geometry is kept in 2-d. 
			Whereas Image Morphing interpolates between \textit{pixel intensity values in fixed locations} the method in this article interpolates between 
			\textit{pixel locations with (relatively) fixed intensity values}.
			\textbf{Question:} Sections read mention that pixel positions are stored in 3d (3-tuple) data structure. I'm not sure I understand this correctly, since 
			\begin{enumerate}
				\item This would effectively make this structure a point cloud (but no mention of it in the paper).
				\item There is no mention of special "depth-based" hardware or cameras (Far as I know this is upposed to be a regular image).
			\end{enumerate}
		}}
		\logentry{4}{30}{2016}{Checked understanding of \textit{epipolar constraint} through reading of [Hartley2004]~\cite{Hartley2004} and its derivation of 
			\begin{equation*}
				\begin{split}
					{\mathbf{'x}^T}\cdot{\mathbf{E}}\cdot\mathbf{x} &= 
					{\mathbf{'x}^T}\cdot{\lbrack\mathbf{t}\rbrack}_{\times}\cdot{\mathbf{R}}\cdot\mathbf{x} \\
					&= {\mathbf{'x}^T}\cdot{'l}
				\end{split}
			\end{equation*}
			and creation of MatLab code verifying this.\newline
			\par I may have been mistaken about relation of \textbf{Fundamental Matrix} and \textbf{Essential Matrix}. \newline
			\par My current understanding is the \textit{Fundamental Matrix} describes point/epipolar line correspondance for images under \textbf{scale invariant} conditions (i.e. point correspondance and Fundamental matrix does not change when one image (or both images) are scaled (uniformly or omni-directionally). \newline
			\par \textit{Essential Matrix} describes point/epipolar line correspondance for images under \textbf{normalized} conditions (i.e. unit-length is set equal to focal-length, and projection center is set at $(0,0,1)$.
		}
		\logentry{5}{2}{2016}{Additional wording to Stereo-vision section. I am unsure of best order to present ideas related to \textit{multi-view} geometry.
		}
%\newpage\\\hline %% e-mail 20160523
		\logentry{5}{18}{2016}{Reviewed [Chen1993]~\cite{Chen1993} Section 2. Consider reviewing follow relevant articles:
			\begin{itemize}
				\item Disparity [Gosh89]
				\item Optical Flow [Nage86]
				\item Look-up tables [Wolb89]
				\item 3d scenes [Pogg91]
			\end{itemize}
			Working on MatLab code to pick correspondig points in stereo-images, and calculate pixel offset vectors.
		}
		\logentry{5}{19}{2016}{Read Section 2.3 of [Chen1993]~\cite{Chen1993}. View interpolation is limited by:
			\begin{itemize}
				\item \textbf{Penumbra}: pixels visible in one source image \textit{but not both}
				\item \textbf{Umbra}, pixels visible in neither source image, and \textit{invisible} in destination image.
				\item \textbf{Holes}, pixels visible in neither source image, but \textit{visible} in destination image.
			\end{itemize}
Calculatred formula for \textit{pre-displaced} quad-pixel calculation using a bi-linear interpolation as:
\begin{equation*}
\mathbf{P}(u,v) = 
\mathbf{P}(0,0)\cdot (1-u)\cdot (1-v)+\mathbf{P}(1,0)\cdot u \cdot (1-v)+
\mathbf{P}(0,1)\cdot (1-u)\cdot v +\mathbf{P}(1,1)\cdot u \cdot v
\end{equation*}
		}
		\logentry{5}{20}{2016}{
Derived formula for 
\textit{uv} calculation using 
\textit{geometry matrix}, \textit{blending matrix} and
\textit{basis vectors} of 
$\mathbf{u}=[u\ 1]^{T}$ and 
$\mathbf{v}=[v\ 1]^{T}$


\begin{equation*}\begin{split}
x_{uv} &= 
\begin{bmatrix}u & 1\end{bmatrix}
\begin{bmatrix}-1 & 1\\ 1 & 0\\\end{bmatrix}
\begin{bmatrix}x_{00} & x_{01} \\ x_{10} & x_{11}\\\end{bmatrix}
\begin{bmatrix}-1 & 1\\ 1 & 0\\\end{bmatrix}
\begin{bmatrix}v \\ 1\\\end{bmatrix}\\
y_{uv} &= 
\begin{bmatrix}u & 1\end{bmatrix}
\begin{bmatrix}-1 & 1\\ 1 & 0\\\end{bmatrix}
\begin{bmatrix}y_{00} & y_{01} \\ y_{10} & y_{11}\\\end{bmatrix}
\begin{bmatrix}-1 & 1\\ 1 & 0\\\end{bmatrix}
\begin{bmatrix}v \\ 1\\\end{bmatrix}\\
\end{split}\end{equation*}

			\par\Kamangar{Is there a way given $x$ and $y$ to solve for $u$ and $v$?}
		}
		\logentry{5}{22}{2016}{
			Added more to thesis document.\newline
			\par Worked on singular-value of previous blending equation. where:

\begin{equation*}
\begin{split}
\begin{bmatrix}x_{uv} & 0 \\ 0 & y_{uv}\\\end{bmatrix}
&=
\begin{bmatrix}\mathbf{u} & \mathbf{0} \\ \mathbf{0} & \mathbf{u} \end{bmatrix}^{T}
\begin{bmatrix}\mathbf{M} & \mathbf{0} \\ \mathbf{0} & \mathbf{M} \end{bmatrix}^{T}
\begin{bmatrix}\mathbf{X} & \mathbf{0} \\ \mathbf{0} & \mathbf{Y} \end{bmatrix}
\begin{bmatrix}\mathbf{M} & \mathbf{0} \\ \mathbf{0} & \mathbf{M} \end{bmatrix}
\begin{bmatrix}\mathbf{v} & \mathbf{0} \\ \mathbf{0} & \mathbf{v} \end{bmatrix}
\end{split}
\end{equation*}

where
\begin{equation*}
\begin{split}
%
\mathbf{u} =\begin{bmatrix}u \\ 1\\\end{bmatrix}
\text{, }
%
\mathbf{v} =\begin{bmatrix}v \\ 1\\\end{bmatrix}
\text{, }
%
\mathbf{X} =\begin{bmatrix}x_{00} & x_{01} \\ x_{10} & x_{11}\\\end{bmatrix}
\text{, }
%
\mathbf{Y} =\begin{bmatrix}y_{00} & y_{01} \\ y_{10} & y_{11}\\\end{bmatrix}
\text{, and }
%
\mathbf{M} =\begin{bmatrix}-1 & 1 \\ 1 & 0\\\end{bmatrix}
\end{split}
\end{equation*}
		}
		\logentry{5}{23}{2016}{
Read [Chen1993]~\cite{Chen1993} section 2.4 on \textit{Block Compression}.\newline\par
\SUMMARY{Blocks are established established by \textit{threshold} where each block contains pixels that are \textit{offset by no more than the threshold}, allowing all pixels to be offset at once.}\newline\par
\Kamangar{Doesn't this assume that all pixels in the block have a uniform offset?}\newline\par
Working on MatLab program to perform pixel offsets of corresponding points (i.e. assign corresponding points to pixels in MatLab by non automatic methods) 


		}
		\logentry{5}{24}{2016}{%
			Read following sections from [Chen1993]~\cite{Chen1993}:
			\begin{itemize}
				\item Implementations (3)
				\begin{itemize}
					\item Preprocessing (3.1)
					\item Interactive Interpolation (3.2)
					\item Examples (3.3)
				\end{itemize}
				\item Applications (4)
				\begin{itemize}
					\item Virtual Reality (4.1)
					\item Motion Blur (4.2)
				\end{itemize}
			\end{itemize}
			\quad\par
			\Kamangar{With regards to Section 3.1 and Section 1, why is a graph structure needed? Why is it a lattice?}\newline\par
			\Kamangar{With regards to Section 4.1, I don't understand the concepts of \textit{temporal anti-aliasing} and \textit{super-sampling}?}
		\newline\par
		Made additional changes / added material to thesis document.
		}
		\logentry{5}{25}{2016}{%
Was using figures from \url{http://www.robots.ox.ac.uk/~vgg/hzbook/hzbook2/HZfigures.html} as test images, which may not be best source as there white borders, appear to be up-sampled, and do not contain (extrinsic) calibration info. Consider using images located at \url{http://vision.middlebury.edu/stereo/data/scenes2014/} that contain meta-info including (intrinsic) calibration info.
		}
		\logentry{5}{29}{2016}{%
Finished [Chen1993]~\cite{Chen1993}. Not sure if remaining article is of consequence.\newline
\par
Finished MatLab program for \textit{animating} / \textit{hand-drawing} (See wording in [Chen1993]~\cite{Chen1993}) offset vectors. Program performs offsets in 2-dimensional space. Conisder adding automatic \textit{feature correspondance} and \textit{z-buffer} information from depth map images avaiable on MiddleBury database.
		}
		\logentry{5}{30}{2016}{%
Point-correspondances do not follow even pattern as indicated in [Chen1993]~\cite{Chen1993}:  \textit{Bi-linear coordinates} and \textit{quad partitionions}; May be better to use \textit{Barycentric coordinates} \ \textit{triangle partitions}.\newline
\par Read on MatLab \texttt{tform}, \texttt{maketform}, and \texttt{Delaunay} triangles for purpose of image partitions.
		}
		\logentry{6}{1}{2016}{%
Read and finished [Park2003]~\cite{Park2003}.\newline
\par \SUMMARY{Multiple sections including \textit{point correspondance} and \textit{interpolation}. 
\textbf{Point correspondance}: Breaks images into rectangular partitions. Gets maximum horizontal and vertical pixel gradients using \textit{Sobel operator} in each partition. The maximum gradient in each partition is thresholded to disregard homogeneous and textured regions. 
\textbf{Interpolation}: The images are partitioned with \textit{Delaunay triangulation} using the point correspondances as triangle vertices.}\newline
\par \Kamangar{Article published seems to be vastly different depending on source (See \texttt{Park2003} folder). ScienceDirect version has more math and detail (maybe too much since it details what a \textit{Sobel filter} is). Why would critical information, including algorithm steps and details, be ommitted?}
		}
		\logentry{6}{2}{2016}{%
Reviewing PDF at \url{https://staff.fnwi.uva.nl/l.dorst/hz/chap11_13.pdf} for information on \textit{tri-focal tensor}. Don't understand \textit{practical} calculation of \textit{fundamental matrix} from \textit{Singular Value Decomposition} and \textit{Linear Least Squares} (i.e. don't understand LLS calculation from SVD).
		}
		\logentry{6}{3}{2016}{%
Working on implementing \textit{triangle patch transform} in MatLap (using previously mentioned \texttt{delaunay}, \texttt{tform}, and \texttt{maketform} functions) needed for [Chen1993]~\cite{Chen1993} and [Park2003]~\cite{Park2003}.
		}
		\logentry{6}{4}{2016}{%
Continuting work on getting triangular patches transformed in MatLab. Will use \texttt{affine2d} and \texttt{imwarp} instead of \texttt{maketform} and \texttt{imtransform}.\newline
\par Spent several hours on a false start trying to implement line drawing on pixel data, in order to implment polygon seperation. Finally found MatLab's \texttt{roipoly} function which does what I need.
		}
		\logentry{6}{5}{2016}{%
Almost done with MatLab triangle interpolation program. Hoping to have something to show Kamangar in the next few days.\newline
\par Was reading up on image-segmentation as a way to improve feature detection through masking. Came accross references to \textbf{spectral clustering} which I still don't understand after data mining class. Was reading tutorial at \url{http://classes.engr.oregonstate.edu/eecs/spring2012/cs534/notes/Spectral.pdf} for starters.
		}
		\logentry{6}{8}{2016}{%
Finalized most recent changes to MatLab program. It performs interpolation (between \textit{source} and \textit{destination} images of triangular patches defined by Delaunay triangularization of point correspondances from stereo images (See \texttt{Wood\_Kamangar/StatusReports/StatusReport\_00/Images}). Delaunay triangularization is performed on the source image only then extended to the corresponding points in the destination image so the arrangement of Delaunay triangles remains the same between images.\newline
\par Summary of results is as follows:
\begin{itemize}
\item Triangles confined to one disparity region (See statue head in \texttt{image\_source.png}, \texttt{image\_destination.png}, and \texttt{truedisp.row3.col3.pgm}) show few artifacts and minimal blurring.
\item Triangles crossing disparity regions or containing pixels occluded in the source or destination images (see camcorder tripod and lamp stand) have visibly more artifacts.\newline
\end{itemize}
\par Started reading first page (\textit{Abstract} and \textit{Introduction} sections) of [Sharstein2002]~\cite{Scharstein2002}.
		}
		\logentry{6}{9}{2016}{%
Continuing to read [Scharstein2002]~\cite{Scharstein2002}.\newline
\par
\SUMMARY{
Disparity can be defined by two ideas:
\begin{itemize}
\item \textit{Human Vision} : Difference in location of features in the left and right eye.
\item \textit{Computer Vision} : Inverse depth. Can be treated as a 3-dimensional projective transformation (collineation or homographyv)of 3-d space (X,Y,Z).
\newline
\end{itemize}
\par Define fllowing terms:
\begin{itemize} 
\item \textbf{Disparity Map}: $d(x,y)$
\item \textbf{Disparity Space}: $(x,y,d)$
\item \textbf{Correspondance}: Pixel $(x,y)$ in reference image $r$ and corresponding pixel $(x',y')$ in matching image $m$ given by $x' = x + s d(x,y)$ and$y' = y$ (assuming horizontal displacement \textit{only}), where $s = \pm 1$ is chose do $d$ is always positive. 
\item \textbf{Disparity Space Image}: Any function or image defined over continous or dispartiy space.
\newline
\end{itemize}
}
		}
		\logentry{6}{11}{2016}{%
Continuing to read [Scharstein2002]~\cite{Scharstein2002}:\newline
\par
\SUMMARY{
Algorithms can be ordered in 4 common subsets:
\begin{enumerate}
\item Matching cost computation;
\item Cost (support) aggregation;
\item Disparity computation / optimization;
\item Disparity refinement;\newline 
\end{enumerate}
\par Two main types of agorithms:
\begin{itemize}
\item \textbf{Local}: Including \textit{Squared Intensity Differences} and \textit{Absolute intensity differences}.
\item \textbf{Global} Includeing \textit{Energy minimizatio}.\newline
\end{itemize}
}
\par Continuing to read up on \textit{Spectral Clustering} and \textit{Laplacian embedding} for uses in image segmentation.
		}
%	\hline
	\end{longtable}

	\newpage

	%% Code below should be used for citations 

%	Longuet-Higgins' Fundamental Matix ~\cite{Longuet-Higgins}
	\bibliography{citations}{}
	\bibliographystyle{unsrt}

\end{document}
