%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% begin week12.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{longtable}{l p{12cm} }
	\logentry{7}{31}{2016}{%
Decided to test \textit{spectral clustering} routines \texttt{fnDistance} and \texttt{fnSimilarity} from \formatdate{5}{6}{2016}. Routines work on small images (approximaltey 100 pixels in size), but are bombing out \texttt{matlab} on larger images since for an image containing \textit{n} pixels, the \textit{Laplacian matrix} would be $n\times n$ in size requiring large amounts of memory. Put functions and test scripts in \texttt{Wood\_Kamangar/StatusReports/StatusReport\_12/}\newline

\par I am looking into other methods of \textit{image segmentation} including \textit{graph-cuts} (described as the "gold-standard").\newline


	}
	\logentry{8}{1}{2016}{%
Started reading [Mark1997]~\cite{Mark1997}.\newline

\par\SUMMARY{Paper describes expanded algorithm for \textit{view interpolation} that building on [Chen1993]~\cite{Chen1993}. Pixels (including \textit{z}-buffer and color information) in source images (referred to in article as \textit{reference frames}) are transformed to the new new frame (referred to in article as \textit{derived frames}) via \textit{Euclidean}-transformations and \textit{Affine}-transformations.\newline

\par The paper addresses problems associated with \textit{holes} being proudced in the derived frame, which result from a number of sources.  They inlcude pixels \textit{occluded} in the reference frame. Another source are surfaces that are highly incident to the image plane in the refence frames, but more closely parallel to the image plane in the derived images. The occurance of holes can be addressed through the use of a \textit{mesh} for surface reprsenation (similar to that resulting from a \textit{point cloud}). This results in holes of the latter type (surfaces of different angles to the image plane) being filled. Holes of the former type (from occluded pixel areas) occur along a siloutte of the backround/foreground surfaces. Normally the mesh results in a distorted surface connecting that foreground and background surface. The proposed algorithm (referred to in the article as \textit{compositing}) addresses this issue by keeping the surfaces distinct and seperate and filling in the missing pixels with those containing the maximum (farthest) \textit{z}-value.\newline
 
}
	}
	\logentry{8}{2}{2016}{%
Finished reading [Mark1997]~\cite{Mark1997}. Still unclear about some aspects including details calculations in section \textbf{4.3 Connectedness Calculation}.\newline

\par\SUMMARY{The compositing algorithm works by transforming the pixels in each \textit{reference} frame to seperate \textit{transformed-reference} frames. Each pixel buffer contain position, \textit{z}-buffer, and color information. Because a multiple pixels from a single \textit{reference} frame can be mapped to the same pixel buffer in its \textit{transformed-reference} frame, pential new pixel values are compared with those already in the pixel buffer, with those pixels containing the closest (minimum) \textit{z}-value remaining in the buffer.\newline

\par Another aspect of the proposed algorithm is the treatment of \textit{rubber surfaces} that occur along the siloutte lines between the foreground and backround segments of the generated mesh surface. This is handled by the notion of \textit{connectedness} of surfaces. Pixels with mesh vertices part of a single object surface are considered to be \textit{highly-connected}, whereas mest trianges covering disjoint and seperate surfaces have \textit{low-connectiveness}.\newline

\par An additional concept the authors make use of is \textit{confidence value}. The article references the confidence value as the ratio of a pixel's \textit{solid angle} in the reference frame to the \textit{solid angle} in the derived frame. It is essentially a measure of how much a surface is parallel to the image plane. Surfaces, whose normal vector turns \textit{towards} the image plane when transforming from the reference frame to derived frame,  result in \textit{pixel holes} and have low confidence values. Sufaces, whos normal vector turns away from the image plane are oversampled and have high confidence values.\newline

\par When selecting pixels for the \textit{derived} frame a number of scenarios arise: If both pixels have high connectedness, the one with closer \textit{Z}-value is used in the derived frame. If the \textit{Z}-values are the same (within a tolerance), the pixel with higher \textit{confidence value} is used. If only one of the pixels has high connectedness, that pixel is selected. If nneither pixel has high connectedness, the pixel with the higher confidence value is used. When dealing mesh triangles of low connectedness, instead of interpolating between the \textit{foreground} and \textit{background} surface textures, the surface texture with the \textit{farthest} \textit{Z}-value is used to approximate the occluded areas.\newline
} 

\par\Kamangar{
I don't understand the explantion given for section \textbf{4.3 Connectedness Calculation}.
}
	}
	
	\logentry{8}{3}{2016}{%
Started reading [Saito2002]~\cite{Saito2002}. I am trying to understand concept of \textit{cross-ratios} for the article material. I also plan to add section regarding \textit{homographies} to thesis document. I put \texttt{MatLab} code in \texttt{Wood\_Kamangar/StatusReports/StatusReport\_12/}

	}

	\logentry{8}{4}{2016}{%
Continued reading [Saito2002]~\cite{Saito2002}. Will need to read [Saito1999]~\cite{Saito1999} for background on \textit{projective grid space}. Summary of [Saito2002]~\cite{Saito2002} follows.\newline

\par\SUMMARY{%
[Saito2002]~\cite{Saito2002} describes a system used in \textit{virtualized television} and \textit{free viewpoint television}, and specifically with regards to televizing soccer matches. It defines a \textit{projective grid space} (PGS) betweens two images $I_1$ and $I_2$. Instead of a cooridinate system where the basis vectors are all \textit{orthoganal}, the PGS defines two of the basis vectors as being along the principal axis of each of the images being interpolated.\newline

\par There exist \textit{fundamental matrices} from $I_1$ to $I_2$ (denoted in the article as $\mathbf{F}_{12}$) and from $I_2$ to $I_1$ (denoted as $\mathbf{F}_{21}$) which transforms points in one image to \textit{epipolar lines} in a the other image. Corresponding points $\mathbf{P}_1$ in $I_1$ and $\mathbf{P}_2$ in $I_2$ can similarly be transformed to epipolar lines in a mid-view image $I_i$ by the fundamental matrices $\mathbf{F}_{1i}$ and $\mathbf{F}_{2i}$. The intersection of the two generated epipolar lines is the position of the corresponding point in $\mathbf{P}_i$ in $I_i$.\newline

\par The viewing angle and position of the interpolated image $I_i$ is confined to the baseline between two images $I_1$ and $I_2$ using \textit{linear interpolation}. When a third image $I_3$ (viewed from a higher angle) is adde, the viewing angle and position are confined to the triangle connecting the optical centers of the 3 image planes using \textit{barycentric interpolations}. The interpolation methods are used for both \textit{pixel position} and \textit{pixel color}.\newline

\par Scene components are divided into 3 major components including:\newline

\par
\begin{itemize}
\item Players and Ball
\item Field ground and goal
\item Background including stands\newline
\end{itemize}

pixel operations dependant on the component type to which it belongs. The \textit{players and ball} component is considered to be \textit{dynamic} since it is changing between fames. The \textit{players and ball} components are actually silloutted areas created from extracting the \textit{field ground and goal} components. The pixels in the intermediate views are determined from interpolating pixel values between boundaries (along the epipolar lines) of the sillouetted areas. The \textit{field ground and goal} components are transformed via \textit{homographies} with the planes corresponding to the \textit{field ground} and sides of the \textit{goal post} treated as seperate planes. \textbf{Although not explicitly stated, I'm guessing pictures of the field ground (without the goal post or players) may  also be taken before hand to account for pixels that might otherwise be occluded (with the inclusion of the players and goal post)}. The remaining area containing the \textit{background and stands} are transformed with \textit{image mosaicing} and a \textit{plane at infinity}. 

}\newline
	}
	\logentry{8}{5}{2016}{%
\UPDATE{
Discussed the matter of memory issues related to \textit{spectral clustering} detailed on \formatdate{31}{7}{2016} with \texttt{levine@uta.edu}. Due to the memory issues related to rendering moderate size images (300x200 pixels) I decided it might be better to:\newline

\par
\begin{enumerate}
\item Downsample original image to manageble size on which \textit{spectral clustering} can be performed.
\item Extract edge regions of down sampled areas.
\item Partition original size image into manageble sub areas. 
\item Perform \textit{spectral clustering} on sub areas corresponding to edge regions extracted from downsampled image.
\item Join sub areas from image partitioning by mapping possibly non-equal segment labels between sub areas.
\end{enumerate}

}



	}
%	\hline
	\end{longtable}

